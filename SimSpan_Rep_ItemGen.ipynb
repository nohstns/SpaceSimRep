{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPqMDIfi52alWGUkFzZG855",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nohstns/SpaceSimRep/blob/main/SimSpan_Rep_ItemGen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pseudoword generation SimSpan Replication\n",
        "This notebook contains the code used to generate the pseudowords used to replicate [Nakata & Suzuki (2019)](https://www.cambridge.org/core/journals/studies-in-second-language-acquisition/article/effects-of-massing-and-spacing-on-the-learning-of-semantically-related-and-unrelated-words/F58BA8D70385603B9C42E408BFCB8A10). We rely on the `Wuggy` package, the [Python implementation](https://wuggycode.github.io/wuggy/) of the algorithm developed by [Keuleers & Brysbaert (2010)](http://crr.ugent.be/papers/Wuggy_BRM.pdf).\n",
        "\n",
        "It takes eight hardcoded vocabulary sets and their corresponding Basque translations or, when the translation was not available in the Basque plugin data, a semantically related alternative. The script outputs a `.csv` file with the following structure:\n",
        "`INDEX  ITEM  SET ENGLISH SOURCE  PSEUDO`\n",
        "\n",
        "The returned dataset has three possible pseudowords per item, meant to be manually selected post-generation to control for possible issues with the generated items.\n",
        "\n",
        "Questions can be sent to nafal@utexas.edu.\n",
        "\n",
        "## Loading packages\n"
      ],
      "metadata": {
        "id": "y9mjiaANLqMG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8iHXVEPIBo_y",
        "outputId": "264bc1d6-a0d8-47b4-ce9e-6d9b646db1d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Wuggy in /usr/local/lib/python3.12/dist-packages (1.1.2)\n",
            "Requirement already satisfied: Levenshtein>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from Wuggy) (0.27.3)\n",
            "Requirement already satisfied: statsmodels>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from Wuggy) (0.14.6)\n",
            "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /usr/local/lib/python3.12/dist-packages (from Levenshtein>=0.12.0->Wuggy) (3.14.3)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.12.1->Wuggy) (2.0.2)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.12.1->Wuggy) (1.16.3)\n",
            "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.12.1->Wuggy) (2.2.2)\n",
            "Requirement already satisfied: patsy>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.12.1->Wuggy) (1.0.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from statsmodels>=0.12.1->Wuggy) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels>=0.12.1->Wuggy) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels>=0.12.1->Wuggy) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas!=2.1.0,>=1.4->statsmodels>=0.12.1->Wuggy) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels>=0.12.1->Wuggy) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install Wuggy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from wuggy import WuggyGenerator\n",
        "from csv import DictWriter"
      ],
      "metadata": {
        "id": "ksz29RcdBxmJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading reference vocabulary"
      ],
      "metadata": {
        "id": "dpkxpztlLmBI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference (English) items"
      ],
      "metadata": {
        "id": "0LjKgIpNJLkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ref_related_set1 = [\"baboon\", \"badger\", \"otter\", \"porcupine\", \"raccoon\", \"weasel\"]\n",
        "ref_related_set2 = [\"diaphragm\", \"intestine\", \"placenta\", \"rectum\", \"tympanum\", \"womb\"]\n",
        "ref_related_set3 = [\"bluff\", \"estuary\", \"plateau\", \"ravine\", \"shoal\", \"strait\"]\n",
        "ref_related_set4 = [\"azalea\", \"camellia\", \"camphor\", \"cedar\", \"magnolia\", \"willow\"]\n",
        "\n",
        "ref_unrelated_set5 = [\"alloy\", \"apparition\", \"kerosene\", \"kiln\", \"plumage\", \"rudder\"]\n",
        "ref_unrelated_set6 = [\"cistern\", \"insurgent\", \"pall\", \"parable\", \"sardine\", \"venom\"]\n",
        "ref_unrelated_set7 = [\"alcove\", \"pail\", \"pigment\", \"potassium\", \"relic\", \"toupee\"]\n",
        "ref_unrelated_set8 = [\"berth\", \"fuselage\", \"ointment\", \"ore\", \"sentry\", \"tuberculosis\"]\n",
        "\n",
        "english_sets = [ref_related_set1, ref_related_set2, ref_related_set3, ref_related_set4,\n",
        "                ref_unrelated_set5, ref_unrelated_set6, ref_unrelated_set7, ref_unrelated_set8]"
      ],
      "metadata": {
        "id": "0RfEIeOeJPPq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source (real Basque words) items"
      ],
      "metadata": {
        "id": "NwpTuR4JJLa1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "source_related_set1 = [\"tximino\", \"azkonar\", \"igaraba\", \"triku\", \"ugaztun\", \"erbinude\"]\n",
        "source_related_set2 = [\"diafragma\", \"heste\", \"plazenta\", \"uzki\", \"tinpano\", \"umetoki\"]\n",
        "source_related_set3 = [\"labar\", \"estuario\", \"ordoki\", \"sakan\", \"saldo\", \"itsasarte\"]\n",
        "source_related_set4 = [\"arrosa\", \"infusio\", \"iraunkor\", \"zedro\", \"lore\", \"sahats\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "XP9-WbFsCCcE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_unrelated_set5 = [\"aleazio\", \"agerpen\", \"erregai\", \"labe\", \"luma\", \"lema\"]\n",
        "source_unrelated_set6 = [\"urtegi\", \"matxinatu\", \"oihal\", \"parabola\", \"sardina\", \"pozoi\"]\n",
        "source_unrelated_set7 = [\"bazter\", \"ontzi\", \"pigmentu\", \"potasio\", \"erlikia\", \"ileorde\"]\n",
        "source_unrelated_set8 = [\"ohatze\", \"hegazkin\", \"ukendu\", \"meatze\", \"zaintzaile\", \"tuberkuloso\"]"
      ],
      "metadata": {
        "id": "4bmbqJ-4DAZk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_sets = [source_related_set1, source_related_set2, source_related_set3, source_related_set4,\n",
        "               source_unrelated_set5, source_unrelated_set6, source_unrelated_set7, source_unrelated_set8]"
      ],
      "metadata": {
        "id": "ldhAKE3nLM01"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Wuggy\n",
        "### Loading algorithm"
      ],
      "metadata": {
        "id": "21DOf0riLjZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = WuggyGenerator()"
      ],
      "metadata": {
        "id": "s5bW2pDlCty7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g.supported_official_language_plugin_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRfiUBW5ECVi",
        "outputId": "08c882ba-e0d4-47c5-a17d-aa32a16ec493"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['orthographic_basque',\n",
              " 'orthographic_dutch',\n",
              " 'orthographic_english',\n",
              " 'orthographic_french',\n",
              " 'orthographic_german',\n",
              " 'orthographic_italian',\n",
              " 'orthographic_polish',\n",
              " 'orthographic_serbian_cyrillic',\n",
              " 'orthographic_serbian_latin',\n",
              " 'orthographic_spanish',\n",
              " 'orthographic_vietnamese',\n",
              " 'orthographic_estonian',\n",
              " 'phonetic_english_celex',\n",
              " 'phonetic_english_cmu',\n",
              " 'phonetic_french',\n",
              " 'phonetic_italian']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "g.load('orthographic_basque')"
      ],
      "metadata": {
        "id": "IU3y9xc3EEH0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preparation"
      ],
      "metadata": {
        "id": "zNVZIBRxQMMu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baa85739"
      },
      "source": [
        "newData = []\n",
        "set_names = [\n",
        "    \"related_set1\", \"related_set2\", \"related_set3\", \"related_set4\",\n",
        "    \"unrelated_set5\", \"unrelated_set6\", \"unrelated_set7\", \"unrelated_set8\"\n",
        "]\n",
        "counter = 1\n",
        "idx_counter = 1\n",
        "ncandidates = 3"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('generatedPseudoWords.csv', 'w', newline=\"\") as csvfile:\n",
        "  fieldnames = ['INDEX', 'ITEM', 'SET', 'ENGLISH', 'SOURCE', 'PSEUDO']\n",
        "  writer = DictWriter(csvfile, fieldnames)\n",
        "\n",
        "  writer.writeheader()"
      ],
      "metadata": {
        "id": "_m3a0KIzaR3v"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generating pseudowords"
      ],
      "metadata": {
        "id": "wFopHEsFTIyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for set_idx, (source_word_list, english_word_list, set_name) in enumerate(zip(source_sets, english_sets, set_names)):\n",
        "    print(f\"Processing Set: {set_name} (Index: {set_idx})\")\n",
        "    for word_idx, (source_word, english_word) in enumerate(zip(source_word_list, english_word_list)):\n",
        "        print(f\"  - Word Pair {word_idx+1}: Source='{source_word}', English='{english_word}'\")\n",
        "\n",
        "        pseudoword_matches = g.generate_classic([source_word])\n",
        "\n",
        "        pseudowords_for_current_source_word = []\n",
        "\n",
        "        for i in range(ncandidates):\n",
        "            if i < len(pseudoword_matches):\n",
        "                pseudowords_for_current_source_word.append(pseudoword_matches[i][\"pseudoword\"])\n",
        "            else:\n",
        "                pseudowords_for_current_source_word.append(\"\")\n",
        "\n",
        "        print(f\"    Generated pseudowords: {pseudowords_for_current_source_word}\")\n",
        "\n",
        "        print(f\"    Storing pseudowords in dataset\")\n",
        "        for pseudo_word in pseudowords_for_current_source_word:\n",
        "          with open('generatedPseudoWords.csv', 'a', newline=\"\") as csvfile:\n",
        "            fieldnames = ['INDEX', 'ITEM', 'SET', 'ENGLISH', 'SOURCE', 'PSEUDO']\n",
        "            writer = DictWriter(csvfile, fieldnames)\n",
        "            writer.writerow({\n",
        "                \"INDEX\": idx_counter,\n",
        "                \"ITEM\": counter,\n",
        "                \"SET\": set_name,\n",
        "                \"ENGLISH\": english_word,\n",
        "                \"SOURCE\": source_word,\n",
        "                \"PSEUDO\": pseudo_word\n",
        "            })\n",
        "            idx_counter += 1\n",
        "        counter += 1\n",
        "        print(f'  Pseudowords for {word_idx+1}. {source_word} stored.\\n')\n",
        "    print(f'Set {set_name} stored.\\n')\n",
        "\n",
        "print('DONE')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0JEENbbLliu",
        "outputId": "19e0c94a-1e95-465d-db56-025c2062580b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing Set: related_set1 (Index: 0)\n",
            "  - Word Pair 1: Source='tximino', English='baboon'\n",
            "    Generated pseudowords: ['tribido', 'tribilo', 'trihido']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 1. tximino stored.\n",
            "\n",
            "  - Word Pair 2: Source='azkonar', English='badger'\n",
            "    Generated pseudowords: ['azpudar', 'azpular', 'aztudar']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 2. azkonar stored.\n",
            "\n",
            "  - Word Pair 3: Source='igaraba', English='otter'\n",
            "    Generated pseudowords: ['odanama', 'odanaca', 'odanasa']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 3. igaraba stored.\n",
            "\n",
            "  - Word Pair 4: Source='triku', English='porcupine'\n",
            "    Generated pseudowords: ['trolu', 'trelu', 'trili']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 4. triku stored.\n",
            "\n",
            "  - Word Pair 5: Source='ugaztun', English='raccoon'\n",
            "    Generated pseudowords: ['ubentun', 'unentun', 'udiltun']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 5. ugaztun stored.\n",
            "\n",
            "  - Word Pair 6: Source='erbinude', English='weasel'\n",
            "    Generated pseudowords: ['enginole', 'enkinole', 'enpinole']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 6. erbinude stored.\n",
            "\n",
            "Set related_set1 stored.\n",
            "\n",
            "Processing Set: related_set2 (Index: 1)\n",
            "  - Word Pair 1: Source='diafragma', English='diaphragm'\n",
            "    Generated pseudowords: ['diaflelba', 'diallilba', 'diallirba']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 1. diafragma stored.\n",
            "\n",
            "  - Word Pair 2: Source='heste', English='intestine'\n",
            "    Generated pseudowords: ['soste', 'suste', 'puste']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 2. heste stored.\n",
            "\n",
            "  - Word Pair 3: Source='plazenta', English='placenta'\n",
            "    Generated pseudowords: ['krabinta', 'krasinta', 'brabinta']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 3. plazenta stored.\n",
            "\n",
            "  - Word Pair 4: Source='uzki', English='rectum'\n",
            "    Generated pseudowords: ['olki', 'ozti', 'oski']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 4. uzki stored.\n",
            "\n",
            "  - Word Pair 5: Source='tinpano', English='tympanum'\n",
            "    Generated pseudowords: ['ternano', 'terbano', 'termano']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 5. tinpano stored.\n",
            "\n",
            "  - Word Pair 6: Source='umetoki', English='womb'\n",
            "    Generated pseudowords: ['unekuke', 'unekuri', 'unekore']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 6. umetoki stored.\n",
            "\n",
            "Set related_set2 stored.\n",
            "\n",
            "Processing Set: related_set3 (Index: 2)\n",
            "  - Word Pair 1: Source='labar', English='bluff'\n",
            "    Generated pseudowords: ['gazar', 'hapar', 'hamar']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 1. labar stored.\n",
            "\n",
            "  - Word Pair 2: Source='estuario', English='estuary'\n",
            "    Generated pseudowords: ['eskoagaa', 'eskoanaa', 'eskoakaa']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 2. estuario stored.\n",
            "\n",
            "  - Word Pair 3: Source='ordoki', English='plateau'\n",
            "    Generated pseudowords: ['onpuki', 'onkuki', 'onguki']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 3. ordoki stored.\n",
            "\n",
            "  - Word Pair 4: Source='sakan', English='ravine'\n",
            "    Generated pseudowords: ['saten', 'satun', 'takin']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 4. sakan stored.\n",
            "\n",
            "  - Word Pair 5: Source='saldo', English='shoal'\n",
            "    Generated pseudowords: ['talto', 'surdo', 'sordo']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 5. saldo stored.\n",
            "\n",
            "  - Word Pair 6: Source='itsasarte', English='strait'\n",
            "    Generated pseudowords: ['ibladardi', 'ibladarki', 'ibladorle']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 6. itsasarte stored.\n",
            "\n",
            "Set related_set3 stored.\n",
            "\n",
            "Processing Set: related_set4 (Index: 3)\n",
            "  - Word Pair 1: Source='arrosa', English='azalea'\n",
            "    Generated pseudowords: ['eklesa', 'eklusa', 'ekloza']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 1. arrosa stored.\n",
            "\n",
            "  - Word Pair 2: Source='infusio', English='camellia'\n",
            "    Generated pseudowords: ['orbujio', 'orbumio', 'orbuhio']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 2. infusio stored.\n",
            "\n",
            "  - Word Pair 3: Source='iraunkor', English='camphor'\n",
            "    Generated pseudowords: ['orailkor', 'orainkar', 'orainkoz']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 3. iraunkor stored.\n",
            "\n",
            "  - Word Pair 4: Source='zedro', English='cedar'\n",
            "    Generated pseudowords: ['modro', 'lello', 'lekro']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 4. zedro stored.\n",
            "\n",
            "  - Word Pair 5: Source='lore', English='magnolia'\n",
            "    Generated pseudowords: ['gere', 'mere', 'gire']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 5. lore stored.\n",
            "\n",
            "  - Word Pair 6: Source='sahats', English='willow'\n",
            "    Generated pseudowords: ['sazets', 'pahits', 'pahuts']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 6. sahats stored.\n",
            "\n",
            "Set related_set4 stored.\n",
            "\n",
            "Processing Set: unrelated_set5 (Index: 4)\n",
            "  - Word Pair 1: Source='aleazio', English='alloy'\n",
            "    Generated pseudowords: ['igaaxia', 'igaadao', 'igaadia']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 1. aleazio stored.\n",
            "\n",
            "  - Word Pair 2: Source='agerpen', English='apparition'\n",
            "    Generated pseudowords: ['aninpen', 'azinpen', 'azunpen']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 2. agerpen stored.\n",
            "\n",
            "  - Word Pair 3: Source='erregai', English='kerosene'\n",
            "    Generated pseudowords: ['errizoi', 'errizei', 'errisau']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 3. erregai stored.\n",
            "\n",
            "  - Word Pair 4: Source='labe', English='kiln'\n",
            "    Generated pseudowords: ['gaze', 'gahe', 'made']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 4. labe stored.\n",
            "\n",
            "  - Word Pair 5: Source='luma', English='plumage'\n",
            "    Generated pseudowords: ['gupa', 'guga', 'mupa']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 5. luma stored.\n",
            "\n",
            "  - Word Pair 6: Source='lema', English='rudder'\n",
            "    Generated pseudowords: ['loga', 'lopa', 'gega']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 6. lema stored.\n",
            "\n",
            "Set unrelated_set5 stored.\n",
            "\n",
            "Processing Set: unrelated_set6 (Index: 5)\n",
            "  - Word Pair 1: Source='urtegi', English='cistern'\n",
            "    Generated pseudowords: ['uztebe', 'uzteme', 'uzteze']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 1. urtegi stored.\n",
            "\n",
            "  - Word Pair 2: Source='matxinatu', English='insurgent'\n",
            "    Generated pseudowords: ['setsigatu', 'setsimatu', 'setsilatu']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 2. matxinatu stored.\n",
            "\n",
            "  - Word Pair 3: Source='oihal', English='pall'\n",
            "    Generated pseudowords: ['euzal', 'eizal', 'eusal']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 3. oihal stored.\n",
            "\n",
            "  - Word Pair 4: Source='parabola', English='parable'\n",
            "    Generated pseudowords: ['garasuda', 'garazuda', 'garamuda']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 4. parabola stored.\n",
            "\n",
            "  - Word Pair 5: Source='sardina', English='sardine'\n",
            "    Generated pseudowords: ['larkida', 'larkila', 'lankina']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 5. sardina stored.\n",
            "\n",
            "  - Word Pair 6: Source='pozoi', English='venom'\n",
            "    Generated pseudowords: ['pegoi', 'pedoi', 'pehoi']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 6. pozoi stored.\n",
            "\n",
            "Set unrelated_set6 stored.\n",
            "\n",
            "Processing Set: unrelated_set7 (Index: 6)\n",
            "  - Word Pair 1: Source='bazter', English='alcove'\n",
            "    Generated pseudowords: ['beztur', 'biztur', 'birter']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 1. bazter stored.\n",
            "\n",
            "  - Word Pair 2: Source='ontzi', English='pail'\n",
            "    Generated pseudowords: ['ontxu', 'ortsi', 'ortzu']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 2. ontzi stored.\n",
            "\n",
            "  - Word Pair 3: Source='pigmentu', English='pigment'\n",
            "    Generated pseudowords: ['piknintu', 'pimnintu', 'pipsintu']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 3. pigmentu stored.\n",
            "\n",
            "  - Word Pair 4: Source='potasio', English='potassium'\n",
            "    Generated pseudowords: ['jikalio', 'jikafio', 'jikajio']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 4. potasio stored.\n",
            "\n",
            "  - Word Pair 5: Source='erlikia', English='relic'\n",
            "    Generated pseudowords: ['alkiria', 'aldiria', 'altiria']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 5. erlikia stored.\n",
            "\n",
            "  - Word Pair 6: Source='ileorde', English='toupee'\n",
            "    Generated pseudowords: ['ileulki', 'ileuxki', 'ileunri']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 6. ileorde stored.\n",
            "\n",
            "Set unrelated_set7 stored.\n",
            "\n",
            "Processing Set: unrelated_set8 (Index: 7)\n",
            "  - Word Pair 1: Source='ohatze', English='berth'\n",
            "    Generated pseudowords: ['odarri', 'odatsi', 'olarri']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 1. ohatze stored.\n",
            "\n",
            "  - Word Pair 2: Source='hegazkin', English='fuselage'\n",
            "    Generated pseudowords: ['lebezkin', 'lenezkin', 'gebizkin']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 2. hegazkin stored.\n",
            "\n",
            "  - Word Pair 3: Source='ukendu', English='ointment'\n",
            "    Generated pseudowords: ['ugildu', 'utildu', 'ubaldu']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 3. ukendu stored.\n",
            "\n",
            "  - Word Pair 4: Source='meatze', English='ore'\n",
            "    Generated pseudowords: ['miarri', 'miatsi', 'zeatsi']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 4. meatze stored.\n",
            "\n",
            "  - Word Pair 5: Source='zaintzaile', English='sentry'\n",
            "    Generated pseudowords: ['sointzaine', 'pauntzaine', 'lailtsaile']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 5. zaintzaile stored.\n",
            "\n",
            "  - Word Pair 6: Source='tuberkuloso', English='tuberculosis'\n",
            "    Generated pseudowords: ['nupenkunodo', 'nudenkunodo', 'zupenkunodo']\n",
            "    Storing pseudowords in dataset\n",
            "  Pseudowords for 6. tuberkuloso stored.\n",
            "\n",
            "Set unrelated_set8 stored.\n",
            "\n",
            "DONE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0eU7U5GGdicY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}